
# Generated by CodiumAI
from scripts.gis_monte_carlo import sample_normal
from scripts.gis_monte_carlo import sample_lognormal
from scripts.gis_monte_carlo import run_simulation
from scripts.gis_monte_carlo import process_mc_results

import numpy as np
import pandas as pd

import pytest

# class TestSampleNormal:

#     # The function returns a numpy array of size n.
#     def test_returns_array_of_size_n(self):
#         low = 0
#         high = 10
#         n = 5
#         result = sample_normal(low, high, n)
#         assert isinstance(result, np.ndarray)
#         assert len(result) == n

#     # The function returns an empty numpy array when n is 0.
#     def test_returns_empty_array_when_n_is_0(self):
#         low = 0
#         high = 10
#         n = 0
#         result = sample_normal(low, high, n)
#         assert isinstance(result, np.ndarray)
#         assert len(result) == 0

# class TestSampleLognormal:

#     def test_returns_array_of_size_n(self):
#         low = 1
#         high = 10
#         n = 5
#         result = sample_lognormal(low, high, n)
#         assert isinstance(result, np.ndarray)
#         assert len(result) == n

#     def test_returns_empty_array_when_n_is_0(self):
#         low = 1
#         high = 10
#         n = 0
#         result = sample_lognormal(low, high, n)
#         assert isinstance(result, np.ndarray)
#         assert len(result) == 0

#     def test_raises_assertion_error_when_low_is_less_than_0(self):
#         low = -1
#         high = 10
#         n = 5
#         with pytest.raises(AssertionError):
#             sample_lognormal(low, high, n)
            
class TestRunSimulation:

    def test_valid_input_returns_result(self):
        crr_adjustment = 1
        time_gathering_water = 2.5
        practical_limit_bicycle = 10
        practical_limit_buckets = 5
        met = 1.2
        result = run_simulation(crr_adjustment, time_gathering_water, practical_limit_bicycle, practical_limit_buckets, met, calculate_distance=False)
        assert isinstance(result, pd.DataFrame)

    def test_invalid_crr_adjustment_raises_assertion_error(self):
        crr_adjustment = "0.5"
        time_gathering_water = 2.5
        practical_limit_bicycle = 10
        practical_limit_buckets = 5
        met = 1.2
        with pytest.raises(AssertionError):
            run_simulation(crr_adjustment, time_gathering_water, practical_limit_bicycle, practical_limit_buckets, met)

    def test_invalid_time_gathering_water_raises_assertion_error(self):
        crr_adjustment = 1
        time_gathering_water = "invalid"
        practical_limit_bicycle = 10
        practical_limit_buckets = 5
        met = 1.2
        with pytest.raises(AssertionError):
            run_simulation(crr_adjustment, time_gathering_water, practical_limit_bicycle, practical_limit_buckets, met)

    def test_invalid_practical_limit_bicycle_raises_assertion_error(self):
        crr_adjustment = 1
        time_gathering_water = 2.5
        practical_limit_bicycle = "invalid"
        practical_limit_buckets = 5
        met = 1.2
        with pytest.raises(AssertionError):
            run_simulation(crr_adjustment, time_gathering_water, practical_limit_bicycle, practical_limit_buckets, met)

    def test_invalid_practical_limit_buckets_raises_assertion_error(self):
        crr_adjustment = 1
        time_gathering_water = 2.5
        practical_limit_bicycle = 10
        practical_limit_buckets = "invalid"
        met = 1.2
        with pytest.raises(AssertionError):
            run_simulation(crr_adjustment, time_gathering_water, practical_limit_bicycle, practical_limit_buckets, met)

    def test_invalid_met_raises_assertion_error(self):
        crr_adjustment = 1
        time_gathering_water = 2.5
        practical_limit_bicycle = 10
        practical_limit_buckets = 5
        met = "invalid"
        with pytest.raises(AssertionError):
            run_simulation(crr_adjustment, time_gathering_water, practical_limit_bicycle, practical_limit_buckets, met)

class TestProcessMCResults:
    @pytest.fixture
    def simulation_results(self):
        # Create sample simulation results
        df1 = pd.DataFrame({"percent_with_water": [0.1, 0.2, 0.3]})
        df2 = pd.DataFrame({"percent_with_water": [0.4, 0.5, 0.6]})
        df3 = pd.DataFrame({"percent_with_water": [0.7, 0.8, 0.9]})
        return [df1, df2, df3]

    def test_calculates_correct_statistics(self, simulation_results):
        process_mc_results(simulation_results, plot=False)

        # Load the saved CSV files
        median_df = pd.read_csv("results/median_results.csv")
        mean_df = pd.read_csv("results/mean_results.csv")
        min_df = pd.read_csv("results/min_results.csv")
        max_df = pd.read_csv("results/max_results.csv")
        percentile_90_df = pd.read_csv("results/90th_percentile_results.csv")
        percentile_5_df = pd.read_csv("results/5th_percentile_results.csv")

        # Check if the calculated statistics are correct
        assert np.isclose(median_df["percent_with_water"].values, np.median([0.1, 0.2, 0.3])).all()
        assert np.isclose(mean_df["percent_with_water"].values, np.mean([0.1, 0.2, 0.3])).all()
        assert np.isclose(min_df["percent_with_water"].values, min([0.1, 0.2, 0.3])).all()
        assert np.isclose(max_df["percent_with_water"].values, max([0.1, 0.2, 0.3])).all()
        assert np.isclose(percentile_90_df["percent_with_water"].values, np.percentile([0.1, 0.2, 0.3], 90)).all()
        assert np.isclose(percentile_5_df["percent_with_water"].values, np.percentile([0.1, 0.2, 0.3], 5)).all()

    def test_saves_results_to_files(self, simulation_results):
        process_mc_results(simulation_results, plot=False)

        # Check if the CSV files are saved
        assert Path("results/median_results.csv").is_file()
        assert Path("results/mean_results.csv").is_file()
        assert Path("results/min_results.csv").is_file()
        assert Path("results/max_results.csv").is_file()
        assert Path("results/90th_percentile_results.csv").is_file()
        assert Path("results/5th_percentile_results.csv").is_file()

    def test_pickles_simulation_results(self, simulation_results):
        process_mc_results(simulation_results, plot=False)

        # Check if the simulation results are pickled
        assert Path("results/simulation_results.pkl").is_file()

    def test_plots_chloropleth_maps_when_plot_is_true(self, simulation_results, mocker):
        # Mock the plot_chloropleth function
        mocker.patch("scripts.gis_monte_carlo.gis.plot_chloropleth")

        process_mc_results(simulation_results, plot=True)

        # Check if the plot_chloropleth function is called for each DataFrame
        assert scripts.gis_monte_carlo.gis.plot_chloropleth.call_count == len(simulation_results)