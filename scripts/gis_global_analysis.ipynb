{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import weightedstats as ws\n",
    "\n",
    "\n",
    "# consider using this for weighted stats: http://www.ccgalberta.com/pygeostat/welcome.html\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and tools used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(var, wts):\n",
    "    \"\"\"Calculates the weighted mean\"\"\"\n",
    "    return np.average(var, weights=wts)\n",
    "\n",
    "def weighted_median_series(val, weight):\n",
    "    \"\"\"Calculates the weighted median\n",
    "    ArithmeticError\n",
    "    If the sum of the weights is zero, or if the weights are not positive.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame({\"val\": val, \"weight\": weight})\n",
    "        df_sorted = df.sort_values(\"val\")\n",
    "        cumsum = df_sorted[\"weight\"].cumsum()\n",
    "        cutoff = df_sorted[\"weight\"].sum() / 2.\n",
    "        result = df_sorted[cumsum >= cutoff][\"val\"].iloc[0]\n",
    "        # return just the value\n",
    "    except:\n",
    "        result = np.nan\n",
    "    return result\n",
    "\n",
    "def weighted_median(df, val_column, weight_column):\n",
    "    \"\"\"Calculates the weighted median\n",
    "    ArithmeticError\n",
    "    If the sum of the weights is zero, or if the weights are not positive.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(val_column)\n",
    "    cumsum = df_sorted[weight_column].cumsum()\n",
    "    cutoff = df_sorted[weight_column].sum() / 2.\n",
    "    return df_sorted[cumsum >= cutoff][val_column].iloc[0]\n",
    "\n",
    "def run_weighted_median_on_grouped_df(df, groupby_column, value_column, weight_column):\n",
    "    \"\"\"Calculate the weighted median of a dataframe grouped by a column.\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame to calculate weighted median on.\n",
    "        groupby_column (str): Column to group by.\n",
    "        value_column (str): Column to calculate weighted median on.\n",
    "        weight_column (str): Column to use as weight.\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with weighted median for each group.\n",
    "    \"\"\"\n",
    "    # initialize empty list\n",
    "    d = []\n",
    "    # loop through each group\n",
    "    for i in df[groupby_column].unique():\n",
    "        df_group = df[df[groupby_column] == i]\n",
    "        # if rows in dataframe are more than 1, calculate weighted median\n",
    "        if len(df_group) > 1:\n",
    "            median = weighted_median(df_group, value_column, weight_column)\n",
    "        else:\n",
    "            median = df_group[value_column].values[0]\n",
    "        d.append(\n",
    "            {\n",
    "                groupby_column: i,\n",
    "                \"median\": median,\n",
    "            }\n",
    "        )\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "\n",
    "def load_data(data_file: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Load data from /data directory\n",
    "    '''\n",
    "    PATH = pathlib.Path().resolve()\n",
    "    DATA_PATH = PATH.joinpath(\"../data\").resolve()\n",
    "    return pd.read_csv(DATA_PATH.joinpath(data_file))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data from CSVs.\n",
    "CSVs created in previous script, which did the cycling mobility on a per country basis\n",
    "\n",
    "### GIS Data From QGIS Export\n",
    "https://ghsl.jrc.ec.europa.eu/download.php?ds=smod <- urbanisation\n",
    "\n",
    "https://www.earthenv.org/topography <- topography\n",
    "\n",
    "https://www.globio.info/download-grip-dataset <- roads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/GIS/export_urb.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m urb_data_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/GIS/export_urb.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m country_data_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/processed/country_data_master_interpolated.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_zones_input \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(urb_data_file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_input \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(country_data_file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Data manipulation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kevin/Documents/ProgrammingIsFun/ALLFED/Water/water-access-gis/water-access/scripts/gis_global_analysis.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Convert dtw_1 from meters to kilometers\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/water-access/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/water-access/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/water-access/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/water-access/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/water-access/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m     f,\n\u001b[1;32m   1220\u001b[0m     mode,\n\u001b[1;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1227\u001b[0m )\n\u001b[1;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/water-access/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/GIS/export_urb.csv'"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "\n",
    "# Load the data\n",
    "urb_data_file = \"../data/GIS/export_urb.csv\"\n",
    "country_data_file = \"../data/processed/country_data_master_interpolated.csv\"\n",
    "\n",
    "df_zones_input = pd.read_csv(urb_data_file)\n",
    "df_input = pd.read_csv(country_data_file)\n",
    "\n",
    "# Data manipulation\n",
    "# Convert dtw_1 from meters to kilometers\n",
    "df_zones_input[\"dtw_1\"] /= 1000 \n",
    "\n",
    "# Set a temporary max walking distance for all countries\n",
    "# TODO: Update this to be bespoke per country\n",
    "df_zones_input[\"max distance walking\"] = 3.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Urban / Rural Data\n",
    "Use the GHS_SMOD_E2020_GLOBE_R2023A_54009_1000_V1_0 dataset.\n",
    "from here: https://ghsl.jrc.ec.europa.eu/download.php?ds=smod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create new binary column for urban / rural. Rural is below 15, Urban above 15\n",
    "df_zones_input[\"urban_rural\"] = np.where(df_zones_input[\"URBAN_1\"] > 15, 1, 0)\n",
    "df_zones_input[\"urban_rural\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage slope.\n",
    "\n",
    "Degrees from earthenv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of slope_1 log scale\n",
    "df_zones_input[\"slope_1\"].hist(bins=100, log=False)\n",
    "\n",
    "# qunaitles of slope_1, do 20 quantiles\n",
    "df_zones_input[\"slope_1\"].quantile(np.arange(0, 1, 0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Roads\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the dataframes\n",
    "Do some manual adjustments to populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this analysis loses some data as the overlap between the rasters is not perfect. To reduce this error, use the 30 arc second data. Too much heavy lifting for my computer to do this at the moment.\n",
    "\n",
    "#merge df_input and df_zones on ISO_CC. This assigns all the country data to each zone.\n",
    "# join inner will remove some of the data that is not in both datasets\n",
    "df_zones = df_zones_input.merge(df_input, left_on=\"ISOCODE\", right_on=\"alpha3\", how=\"inner\")\n",
    "\n",
    "# these are the columns\n",
    "# alpha3,Unnamed: 0,Entity,Population,YearPBO,PBO,Terrain Ruggedness,Urban %,Urban Agg %,RoadQuality,Km,Urb %,Average household size (number of members),National At Least Basic,National Limit (more than 30 mins),National Unimproved,National Surface Water,Nat Accesible On Premises,Nat Piped,Nat NonPiped,No. HPs,Year of HP estimate,2015 (C),No. HPs in 2015,Non-functional HPs,Functional HPS,Risk Score,alpha2,region,subregion,borders,Mean BMI (male),Mean BMI (female),Mean male height (cm),Mean female height (cm),women weight,men weight,percent_insufficient_activity,Average Weight,power,Crr,trip_velocity_mean,unloaded_velocity_mean,loaded_velocity_mean,velocitykgs,water_ration_kms\n",
    "\n",
    "#adjust population to account for 9 values per raster point (2.5 to 5 arc min resoltuions. 9 values per point)\n",
    "df_zones[\"AdjPopFloat\"] = df_zones[\"pop_count_15_1\"] / 9 \n",
    "\n",
    "# # convert population density to percent of national population on a per country basis, grouped by ISO_CC\n",
    "df_zones[\"pop_density_perc\"] = df_zones.groupby(\"ISOCODE\")[\"AdjPopFloat\"].apply(lambda x: x / x.sum())\n",
    "\n",
    "# multiply population density by population on a per country basis\n",
    "df_zones[\"pop_zone\"] = df_zones[\"pop_density_perc\"] * df_zones[\"Population\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the population in each zone\n",
    "df_zones[\"country_pop_raw\"] = df_zones.groupby(\"ISOCODE\")[\"pop_zone\"].transform(\"sum\")\n",
    "df_zones[\"country_pop_ratio\"] = df_zones.groupby(\"ISOCODE\")[\"AdjPopFloat\"].transform(\"sum\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Road Analysis from GRIP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dominant_road(row):\n",
    "    if row.sum() == 0 or row.isna().all():\n",
    "       'No Roads'\n",
    "    else:\n",
    "        return row.idxmax()\n",
    "\n",
    "\n",
    "def find_first_non_zero_road(row):\n",
    "    columns_in_hierarchy = [\"grip_1_1\", \"grip_2_1\", \"grip_3_1\", \"grip_4_1\", \"grip_5_1\"]\n",
    "    for col in columns_in_hierarchy:\n",
    "        if row[col] != 0:\n",
    "            return col\n",
    "    return 'No Roads'\n",
    "\n",
    "\n",
    "df_zones['dominant_road_type'] = df_zones[[\"grip_1_1\", \"grip_2_1\", \"grip_3_1\", \"grip_4_1\", \"grip_5_1\"]].apply(find_first_non_zero_road, axis=1)\n",
    "\n",
    "df_zones['dominant_road_type'] = df_zones['dominant_road_type'].replace({\n",
    "    'grip_1_1': 'Highways',\n",
    "    'grip_2_1': 'Primary Roads',\n",
    "    'grip_3_1': 'Secondary Roads',\n",
    "    'grip_4_1': 'Tertiary Roads',\n",
    "    'grip_5_1': 'Local Roads'\n",
    "})\n",
    "\n",
    "\n",
    "# histogram of dominant road type\n",
    "df_zones['dominant_road_type'].value_counts().plot(kind='bar')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radnomly sample 1000 points from the dataframe, only the columns related to roads:\n",
    "# grip_1_1, grip_2_1, grip_3_1, grip_4_1, grip_5_1, dominant_road_type\n",
    "df_zones_roads = df_zones[[\"grip_1_1\", \"grip_2_1\", \"grip_3_1\", \"grip_4_1\", \"grip_5_1\", \"dominant_road_type\"]]#.sample(n=10000, random_state=1)\n",
    "\n",
    "# # filtered dataframe of grip_1_1 > 0\n",
    "# df_zones_roads_grip_1_1 = df_zones_roads[df_zones_roads[\"grip_1_1\"] > 0]\n",
    "\n",
    "\n",
    "# # plot histogram of dominant road type\n",
    "# df_zones_roads_grip_1_1['dominant_road_type'].value_counts().plot(kind='bar')\n",
    "\n",
    "\n",
    "# # df_zones_roads[df_zones_roads[\"grip_1_1\"] > 0]\n",
    "\n",
    "\n",
    "df_zones_roads.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zones['dominant_road_type'].value_counts().plot(kind='bar')\n",
    "\n",
    "# histogram og househould\n",
    "# df_zones['Average household size (number of members)'].hist(bins=100)\n",
    "\n",
    "# export to csvdf_zones:\n",
    "# df_zones.to_csv('../data/df_zones.csv')\n",
    "\n",
    "# plot average household size in increasing order using plotly\n",
    "# fig = px.line(df_input.sort_values(by='Average household size (number of members)'), x=\"Entity\", y=\"Average household size (number of members)\", color=\"subregion\")\n",
    "# # px.line(df_input.sort_values(by='Average household size (number of members)')['Average household size (number of members)'])\n",
    "# # save plot\n",
    "# fig.write_html(\"../data/average_household_size.html\")\n",
    "\n",
    "\n",
    "# create a new series with the 'inhabited vrm' values. THis uses any_pop, put over the top of the vrm values, 'vrm1'\n",
    "# find non zero values AdjPopFloat\n",
    "df_zones[\"any_pop\"] = df_zones[\"AdjPopFloat\"].apply(\n",
    "    lambda x: 1 if x > 10 else 0\n",
    ")\n",
    "\n",
    "\n",
    "df_zones[\"any_pop\"].describe()\n",
    "\n",
    "# describe vrm filtered by any_pop =1\n",
    "df_zones[df_zones[\"any_pop\"] == 1][\"slope_1\"].describe()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The section below calculates the population per zone that can reach water\n",
    "\n",
    "Consider putting in household size and bike sharing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zones[\"max distance cycling\"] needs to use the road type and slope to select appropriate value from tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # population with piped water\n",
    "\n",
    "# set df_zones[\"zone_pop_piped\"] to 0 for all zones to begin with\n",
    "df_zones[\"zone_pop_piped\"] = 0\n",
    "\n",
    "# if urban use urban piped and unpiped, if rural use rural piped and unpiped\n",
    "# use the urban_rural column to do this (where urban_rural = 1, use urban, where urban_rural = 0, use rural)\n",
    "df_zones[\"zone_pop_piped\"] = df_zones[\"pop_zone\"] * df_zones[\"urban_rural\"] * df_zones[\"URBANPiped\"]/100 + df_zones[\"pop_zone\"] * (1-df_zones[\"urban_rural\"]) * df_zones[\"RURALPiped\"]/100\n",
    "df_zones[\"zone_pop_unpiped\"] = df_zones[\"pop_zone\"] * df_zones[\"urban_rural\"] * df_zones[\"URBANNon-piped\"]/100 + df_zones[\"pop_zone\"] * (1-df_zones[\"urban_rural\"]) * df_zones[\"RURALNon-piped\"]/100\n",
    "\n",
    "\n",
    "# is it possible to reach water with walking/cycling\n",
    "df_zones[\"zone_cycling_okay\"] = (df_zones[\"dtw_1\"] < df_zones[\"max distance cycling\"])*1 # multiply by 1 to force to binary not true/false\n",
    "df_zones[\"zone_walking_okay\"] = (df_zones[\"dtw_1\"] < df_zones[\"max distance walking\"])*1\n",
    "\n",
    "# how many people can collect water in the zone\n",
    "df_zones[\"fraction_of_zone_with_cycling_access\"] = df_zones[\"zone_cycling_okay\"]* (df_zones[\"PBO\"])/100\n",
    "df_zones[\"fraction_of_zone_with_walking_access\"] = df_zones[\"zone_walking_okay\"] * 1\n",
    "\n",
    "#\n",
    "df_zones[\"population_piped_with_cycling_access\"] = df_zones[\"fraction_of_zone_with_cycling_access\"] * df_zones[\"zone_pop_piped\"]\n",
    "df_zones[\"population_piped_with_walking_access\"] = df_zones[\"fraction_of_zone_with_walking_access\"] * df_zones[\"zone_pop_piped\"]\n",
    "\n",
    "# select the maximum between the two, if walkable, max will always be walking\n",
    "df_zones[\"population_piped_with_access\"] = df_zones[[\"population_piped_with_cycling_access\", \"population_piped_with_walking_access\"]].max(axis=1)\n",
    "\n",
    "# zone pop without water\n",
    "df_zones[\"zone_pop_with_water\"] =  df_zones[\"population_piped_with_access\"] + df_zones[\"zone_pop_unpiped\"]\n",
    "df_zones[\"zone_pop_without_water\"] = df_zones[\"pop_zone\"] - df_zones[\"zone_pop_with_water\"]\n",
    "\n",
    "\n",
    "# use water_ration_kms to calculate the water ration achievable per bike per zone\n",
    "df_zones[\"water_rations_per_bike\"] = df_zones[\"water_ration_kms\"] / df_zones[\"dtw_1\"]\n",
    "\n",
    "# number oif bikes per zone is population divided by household nuymber multipled by PBO\n",
    "df_zones[\"bikes_in_zone\"] = df_zones[\"pop_zone\"] / df_zones[\"Average household size (number of members)\"] * df_zones[\"PBO\"]\n",
    "\n",
    "#water rations achievable utilising all the bikes in the zone is the number of bikes in the zone multiplied by the water rations per bike\n",
    "df_zones[\"water_rations_achievable\"] = df_zones[\"bikes_in_zone\"] * df_zones[\"water_rations_per_bike\"]\n",
    "\n",
    "# population w\n",
    "\n",
    "\n",
    "# NOTE this has the t = 8_hours baked in to it. This could be wrong, maybe we should use daylight hours instead? If the bikes are being shared.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group the zones in to country groups\n",
    "Use groupby agg and then apply to summarise the zone data in to country level, then create some summary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use groupby to create dataframe of country level data from df_zones\n",
    "df_countries = df_zones.groupby(\"ISOCODE\").agg({\n",
    "    \"Entity\":\"first\",\n",
    "    \"country_pop_raw\": \"first\",\n",
    "    \"zone_pop_with_water\":\"sum\",\n",
    "    \"zone_pop_without_water\":\"sum\",\n",
    "    \"population_piped_with_access\":\"sum\"  ,\n",
    "    \"population_piped_with_cycling_access\":\"sum\",\n",
    "    \"population_piped_with_walking_access\":\"sum\",\n",
    "    \"Nat Piped\":\"first\",\n",
    "    \"region\":\"first\",\n",
    "    \"subregion\":\"first\",\n",
    "    # call the weighted median function on the column\n",
    "}).reset_index()\n",
    "\n",
    "# use groupby to create weighted median, needs to be speerate from the above groupby as it uses apply, which can't be used in the same groupby\n",
    "# needs to use apply because the function required two columns as input\n",
    "df_median_group = df_zones.groupby(['ISOCODE']).apply(lambda x : pd.Series({'weighted_med':weighted_median(x,\"dtw_1\",\"pop_zone\")}))\n",
    "\n",
    "# merge the weighted median back into the df_countries dataframe\n",
    "df_countries = df_countries.merge(df_median_group, on=\"ISOCODE\")\n",
    "\n",
    "# drop rows from the dataframe that have Nan in pop_zone and dtw_1\n",
    "df_zones = df_zones.dropna(subset=[\"pop_zone\", \"dtw_1\"])\n",
    "\n",
    "# create summary columns\n",
    "#rename zone columns to country\n",
    "df_countries = df_countries.rename(columns={\"zone_pop_with_water\":\"country_pop_with_water\", \"zone_pop_without_water\":\"country_pop_without_water\"})\n",
    "# create percent\n",
    "df_countries[\"percent_with_water\"] = df_countries[\"country_pop_with_water\"] / df_countries[\"country_pop_raw\"] * 100\n",
    "df_countries[\"percent_without_water\"] = df_countries[\"country_pop_without_water\"] / df_countries[\"country_pop_raw\"] * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data from spurious country values\n",
    "# uses libya as the max possible diatnce to water (from Kummu paper results)\n",
    "\n",
    "# remove any nan rows\n",
    "df_countries = df_countries.dropna()\n",
    "\n",
    "\n",
    "# first pass clean up\n",
    "\n",
    "# remove any rows where the median is more than 1km more than \"LBY\" (Libya)'s median\n",
    "max_distance = df_countries.loc[df_countries[\"ISOCODE\"] == \"LBY\", \"weighted_med\"].values[0] + 1\n",
    "countries_further_than_libya = df_countries[df_countries[\"weighted_med\"] > max_distance]\n",
    "df_countries = df_countries[df_countries[\"weighted_med\"] < max_distance]\n",
    "\n",
    "####### Manual remove countries ###############\n",
    "# inspecting the results, there are a few countries that are clearly wrong, remove them manually\n",
    "list_of_countries_to_remove = [\"GUM\", \"ASM\", \"TON\", \"MNP\", \"ATG\", \"DMA\", \"ABW\", \"BRB\"]\n",
    "df_of_countries_to_remove = df_countries[df_countries[\"ISOCODE\"].isin(list_of_countries_to_remove)]\n",
    "df_countries = df_countries[~df_countries[\"ISOCODE\"].isin(list_of_countries_to_remove)]\n",
    "##############################\n",
    "\n",
    "\n",
    "# summary of removed countries\n",
    "print(\"Countries removed from analysis\")\n",
    "print(countries_further_than_libya[[\"Entity\", \"weighted_med\"]])\n",
    "print(\"Countries removed manually\")\n",
    "print(df_of_countries_to_remove[[\"Entity\", \"weighted_med\"]])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and Visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create choropleth map of population with water from df_country\n",
    "\n",
    "hover_data_list =[\n",
    "    \"Entity\",\n",
    "    \"country_pop_raw\",\n",
    "    \"country_pop_with_water\",\n",
    "    \"country_pop_without_water\",\n",
    "    \"population_piped_with_access\",\n",
    "    \"population_piped_with_cycling_access\",\n",
    "    \"population_piped_with_walking_access\",\n",
    "    \"percent_without_water\",\n",
    "    \"percent_with_water\",\n",
    "    \"Nat Piped\",\n",
    "    \"region\",\n",
    "    \"subregion\",\n",
    "    \"weighted_med\"\n",
    "    ]\n",
    "\n",
    "\n",
    "choro = px.choropleth(\n",
    "    title=\"Percent of Population Has to Relocate\",\n",
    "    data_frame=df_countries,\n",
    "    locations=\"ISOCODE\",\n",
    "    height=600,\n",
    "    color=\"percent_without_water\",\n",
    "    hover_name=\"Entity\",\n",
    "    hover_data=hover_data_list\n",
    ")\n",
    "choro.layout.coloraxis.colorbar.title = ''\n",
    "choro.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bubble chart from df_countries comprising: access to water, piped water, and using population as the size of the bubble\n",
    "# create a new column for the size of the bubble\n",
    "df_countries[\"bubble_size\"] = df_countries[\"country_pop_raw\"] / 1000000 +50\n",
    "\n",
    "# create a new column for the color of the bubble\n",
    "df_countries[\"bubble_color\"] = df_countries[\"Nat Piped\"]\n",
    "\n",
    "# create a new column for the text of the bubble\n",
    "df_countries[\"bubble_text\"] = df_countries[\"Entity\"]\n",
    "\n",
    "px.scatter(df_countries, x=\"percent_without_water\", y=\"Nat Piped\", size=\"bubble_size\", color=\"region\", hover_name=\"bubble_text\", title=\"Access to Water vs. Piped Water vs. Population\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above graph is the money shot. NMeed to fix bubble sizes, maybe add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the countries by distance to water, plot the results\n",
    "df_countries.sort_values(by=\"weighted_med\", inplace=True)\n",
    "# add log scale\n",
    "px.line(df_countries, x=\"Entity\", y=\"weighted_med\", color=\"subregion\", title=\"Distance to Water\", log_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the countries by population withgout water and percent without water\n",
    "px.scatter(df_countries, x=\"percent_without_water\", y=\"country_pop_without_water\", size=\"bubble_size\", color=\"region\", hover_name=\"bubble_text\", title=\"Population vs. Percent Without Water\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics of zones by for slected country\n",
    "# select country\n",
    "country = \"CAF\"\n",
    "\n",
    "# interertsinbg ciolumns\n",
    "interesting_cols =[\n",
    "    \"Entity\",\n",
    "    \"dtw_1\",\n",
    "    \"pop_zone\",\n",
    "    \"country_pop_raw\",\n",
    "    \"population_piped_with_access\",\n",
    "    \"population_piped_with_cycling_access\",\n",
    "    \"population_piped_with_walking_access\",\n",
    "    \"Nat Piped\",\n",
    "    \"region\",\n",
    "]\n",
    "\n",
    "other_cols = [\n",
    "    \"zone_pop_unpiped\",\n",
    "    \"zone_pop_piped\",\n",
    "    \"pop_zone\"\n",
    "\n",
    "]\n",
    "\n",
    "# create dataframe of zones for selected country\n",
    "df_zones_country = df_zones[df_zones[\"ISOCODE\"] == country]\n",
    "df_zones_country = df_zones_country[other_cols]\n",
    "\n",
    "# create summary statistics\n",
    "df_zones_country.describe()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked bar chart, stacking  \"country_pop_with_water\", and \"country_pop_without_water\" on the y axis as two bars. Using region as the x axis.\n",
    "# px.bar(df_countries, x=\"region\", y=[\"country_pop_with_water\", \"country_pop_without_water\"], title=\"Population with Water vs. Population without Water\", hover_data=[\"Entity\"])\n",
    "\n",
    "# create the same, but put the bars side by side\n",
    "px.bar(df_countries, x=\"region\", y=[\"country_pop_with_water\", \"country_pop_without_water\"], barmode=\"group\", title=\"Population with Water vs. Population without Water\", hover_data=[\"Entity\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c09a8b249899dc4589e662892666698668e7a3ca1327801a18c24efb244ad2c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
